{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and cleaning scraped data\n",
    "\n",
    "## Brief explanation \n",
    "\n",
    "**English version**  \n",
    "We collected the data on the website https://immobilier.lefigaro.fr/ for the 3 biggest french cities: Paris, Lyon, Marseille. Scrapping was done by a fellow student, Foudil.\n",
    "\n",
    "The output of the scraper was a .txt file for each of the 3 cities. The outputs of the scraper were inconsistent, because some appartments were listed as houses, some houses as appartments; we also had listings of parking spaces, offices etc. We'll tackle the cleaning of the file and the setup of the dataset in this notebook. Ideally, we would create a pipeline for extracting, transforming, cleaning and loading the data, in a .py script. But for this academic/personal project we're gonna stick to a notebook.\n",
    "\n",
    "**French version**  \n",
    "Nous avons collecté des données sur le site web https://immobilier.lefigaro.fr/ pour les 3 plus grandes villes de France : Paris, Lyon et Marseille. Le scrapping a été éffectué par mon collègue, Foudil. \n",
    "\n",
    "Le résultat de notre collecte de données était un fichier .txt pour chacune des 3 villes. Les résultats de la collecte étaient inconsistants, car certains appartements étaient listés comme des maisons, certaines maisons comme des appartements, et nous avions également des listes de places de parking, de bureaux, etc. Je vais m'attaquer au nettoyage des fichiers et à la mise en place du dataframe/dataset dans ce notebook. Idéalement, je devrais créer un script .py, avec une pipeline pour extraire, transformer, nettoyer et charger les données. Mais pour ce projet académique/personnel, je vais rester sur un notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions\n",
    "\n",
    "**EN**  \n",
    "Below are defined all the functions that we're going to use to clean the data. Docstrings are available for each function.  \n",
    "**FR**  \n",
    "Ci-dessous sont définies toutes les fonctions que nous allons utiliser pour nettoyer les données. Des docstrings sont disponibles pour chaque fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_replace(string:str, str_to_replace=None, replace_with=None) -> str:\n",
    "    \"\"\"\n",
    "    Replace the occurrences of a substring in a given string with a replacement string.\n",
    "\n",
    "    Args:\n",
    "        string (str): The input string to be processed.\n",
    "        str_to_replace (str): The substring to be replaced in the input string. If not provided, defaults to None.\n",
    "        replace_with (str): The replacement string that will be used to replace the occurrences of the substring. If not provided, defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: The modified string after replacing the occurrences of the substring with the replacement string.\n",
    "    \"\"\"\n",
    "    string = string.replace(str_to_replace, replace_with)\n",
    "    return string\n",
    "\n",
    "def file_read(file_name:str) -> List[str]:\n",
    "    \"\"\" Read the file and return the lines\"\"\"\n",
    "    with open(file_name) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "def create_copy(orig_file_name: str, orig_file_folder:str, output_folder_for_copy: str) -> None:\n",
    "    \"\"\"Create a copy of the original files\"\"\"\n",
    "    if not os.path.exists(output_folder_for_copy):\n",
    "        os.mkdir(output_folder_for_copy)\n",
    "    orig_file_path = os.path.join(orig_file_folder, orig_file_name)\n",
    "    copied_file_path = os.path.join('cleaned_data', os.path.basename(orig_file_path))\n",
    "    with open(orig_file_path, 'r') as o_f, open(copied_file_path, 'w') as c_f:\n",
    "        c_f.writelines(o_f.readlines())\n",
    "\n",
    "def file_write(file_name:str, list_to_replace=None, list_replace_with=None)-> None:\n",
    "    \"\"\"\n",
    "    Read a file, replace the specified substrings in its lines, and overwrite the original file.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The path to the file to be read and overwritten.\n",
    "        list_to_replace (list): A list of substrings to be replaced in each line of the file. If not provided, defaults to None.\n",
    "        list_replace_with (list): A list of replacement strings that will be used to replace the corresponding substrings in the file. If not provided, defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        None: The function overwrites the original file and does not return a value.\n",
    "    \"\"\"\n",
    "\n",
    "    lines = file_read(file_name)\n",
    "    with open(file_name, 'w') as f:\n",
    "        for line in lines:\n",
    "            for tr, rw in zip(list_to_replace, list_replace_with):\n",
    "                line = string_replace(string=line, str_to_replace=tr, replace_with=rw)\n",
    "            f.write(line)\n",
    "\n",
    "\n",
    "def prop_printer(file_name:str, df_name:str, n_semicolons:int) -> None:\n",
    "    \"\"\"\n",
    "    Prints the proportion of lines in a file that contain a different number of semicolons than n_semicolons.\n",
    "\n",
    "    Args:\n",
    "    - file_name (str): The name of the file to be processed.\n",
    "    - n_semicolons (int): The number of semicolons to be searched for in each line.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    list_obj = []\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line.count(';')!=n_semicolons:\n",
    "            list_obj.append(line)\n",
    "    if len(lines)>0:\n",
    "        print(f\"Proportion of flagged lines for {df_name}: {len(list_obj)/len(lines)*100:.2f} %\")\n",
    "    else:\n",
    "        print(\"The file is empty\")\n",
    "\n",
    "def val_inval_lists(file_name: str, n_semicolons: int) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Separates the lines in a file into two lists based on the number of semicolons in each line.\n",
    "\n",
    "    Args:\n",
    "    - file_name (str): The name of the file to be processed.\n",
    "    - n_semicolons (int): The number of semicolons to be searched for in each line.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple of two lists of strings. The first list contains the lines that have the specified number of semicolons,\n",
    "      while the second list contains the lines that do not have the specified number of semicolons.\n",
    "    \"\"\"\n",
    "    valid_list = []\n",
    "    invalid_list = []\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line.count(';')== n_semicolons:\n",
    "            valid_list.append(line)\n",
    "        else:\n",
    "            invalid_list.append(line)\n",
    "    return valid_list, invalid_list\n",
    "\n",
    "def drop_nonconform_lines(file_name:str, n_semicolons:int)->None:\n",
    "    \"\"\"\n",
    "    Drops lines from a file that do not have the specified number of semicolons.\n",
    "\n",
    "    Args:\n",
    "    - file_name (str): The name of the file to be processed.\n",
    "    - n_semicolons (int): The number of semicolons to be searched for in each line.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    Raises:\n",
    "    - FileNotFoundError: If the specified file is not found.\n",
    "    - TypeError: If the specified file is not a string or if n_semicolons is not an integer.\n",
    "    \"\"\"\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    with open(file_name, 'w') as f:\n",
    "        for line in lines:\n",
    "            if line.count(';')==n_semicolons:\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the contents of the text files\n",
    "**EN**  \n",
    "We're going to analyze the contents of the text files to have an idea of the missing values and non-conform lines. I decided to separate the data in 3 fields: Information about the listing, Information about the size of the listing, Price. This is done for all 3 files. Each line should contain exactly these 3 fields, that's why our function checks for 2 semicolons and separates invalid lines from valid lines. \n",
    "We then print a message about the % of non-conform lines to look further into what's causing the issue.  \n",
    "**FR**  \n",
    "Nous allons analyser le contenu des fichiers texte pour avoir une idée des valeurs manquantes et des lignes non conformes. J'ai décidé de séparer les données en 3 champs : Information sur l'annonce, Information sur la taille de la propriété, Prix. Cela est fait pour les 3 fichiers. Chaque ligne doit contenir exactement ces 3 champs, c'est pourquoi notre fonction vérifie la présence de 2 points-virgules et sépare les lignes invalides des lignes valides. Nous affichons ensuite un message sur le pourcentage de lignes non conformes pour examiner ce qui pose des problèmes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of flagged lines for Paris: 2.27 %\n",
      "Proportion of flagged lines for Lyon: 5.35 %\n",
      "Proportion of flagged lines for Marseille: 11.42 %\n"
     ]
    }
   ],
   "source": [
    "chars_to_replace = ['ème', 'è', 'é', '€', 'm²', ' (75)', ' (69)', ' (13)', 'Terrain', 'terrain', 'er']\n",
    "replace_chars_with_paris = [';', 'e', 'e', 'eur', 'm2', '', '', '', ';']\n",
    "replace_chars_with = [';', 'e', 'e', 'eur', 'm2;', '', '', '', '','',';']\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd = os.path.normpath(cwd).replace('\\\\', '/')\n",
    "orig_path = cwd + '/original_data'\n",
    "paris = orig_path + '/annuaire_paris.txt'\n",
    "lyon = orig_path + '/annuaire_lyon.txt'\n",
    "marseille = orig_path + '/annuaire_marseille.txt'\n",
    "\n",
    "output_path = cwd + '/cleaned_data'\n",
    "files = [paris, lyon, marseille]\n",
    "for file in files:\n",
    "    create_copy(orig_file_name = file, orig_file_folder = orig_path, output_folder_for_copy=output_path)\n",
    "\n",
    "paris = output_path + '/annuaire_paris.txt'\n",
    "lyon = output_path + '/annuaire_lyon.txt'\n",
    "marseille = output_path + '/annuaire_marseille.txt'\n",
    "\n",
    "file_write(paris, chars_to_replace, replace_chars_with_paris)\n",
    "file_write(lyon, chars_to_replace, replace_chars_with)\n",
    "file_write(marseille, chars_to_replace, replace_chars_with)\n",
    "\n",
    "prop_printer(paris, 'Paris', 2)\n",
    "prop_printer(lyon,'Lyon', 2)\n",
    "prop_printer(marseille, 'Marseille', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digging further \n",
    "**EN**   \n",
    "We'll dig further into understanding why our function flagged **2.27%**, **5.35%**, **11.42%** lines of each respective file. To do so, we're looking to filter listings that contain the word `appartement` and separate them into 2 lists: *Valid* and *Invalid*. We then print the proportion of flagged appartments. (As mentioned above, our scraper output contains parking lots, office spaces, houses, etc.)  \n",
    "**FR**   \n",
    "Nous allons chercher à compréndre le(s) motif(s) pour lequel(s) notre fonction a signalé **2.27%**, **5.35%** et **11.42%** des lignes comme non-conformes. Pour cela, nous allons filtrer les annonces qui contiennent le mot `appartement` et les séparer en deux listes : *Valide* et *Invalide*. Nous afficherons ensuite la proportion d'appartements signalés. (Comme mentionné précédemment, la sortie de notre scraper contient des parkings, des bureaux, des maisons, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The appartments that were flagged as invalid in Lyon file represent 1.42% of the dataset\n"
     ]
    }
   ],
   "source": [
    "lyon_val, lyon_inval = val_inval_lists(lyon, 2)\n",
    "lyon_appart_list = []\n",
    "for i,val in enumerate(lyon_inval):\n",
    "    if 'appartement' in val:\n",
    "        lyon_appart_list.append(val)\n",
    "print(f\"The appartments that were flagged as invalid in Lyon file represent \\\n",
    "{100*len(lyon_appart_list)/(len(lyon_val)+len(lyon_inval)):.2f}% of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The appartments that were flagged as invalid in Marseille file represent 1.83% of the dataset\n"
     ]
    }
   ],
   "source": [
    "marseille_val, marseille_inval = val_inval_lists(marseille, 2)\n",
    "marseille_appart_list = []\n",
    "for i,val in enumerate(marseille_inval):\n",
    "    if 'appartement' in val:\n",
    "        marseille_appart_list.append(val)\n",
    "print(f\"The appartments that were flagged as invalid in Marseille file represent \\\n",
    "{100*len(marseille_appart_list)/(len(marseille_val)+len(marseille_inval)):.2f}% of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The appartments that were flagged as invalid in Paris file represent 2.24% of the dataset\n"
     ]
    }
   ],
   "source": [
    "paris_val, paris_inval = val_inval_lists(paris, 2)\n",
    "paris_appart_list = []\n",
    "for i, val in enumerate(paris_inval):\n",
    "    if 'appartement' in val:\n",
    "        paris_appart_list.append(val)\n",
    "print(f\"The appartments that were flagged as invalid in Paris file represent \\\n",
    "{100*len(paris_appart_list)/(len(paris_val)+len(paris_inval)):.2f}% of the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why dropping the lines?\n",
    "**EN**  \n",
    "Dropping lines without further analysis is not a good practice. But for the sake of simplicity, we're going to do it here, since the non-conform appartments represent less than 3 % in all files.  \n",
    "**FR**  \n",
    "Supprimer des lignes sans analyse supplémentaire n'est pas une bonne pratique. Mais pour simplifier les choses, nous allons le faire ici, car les appartements non conformes représentent moins de 3 % dans tous les fichiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of flagged lines for Paris: 0.00 %\n",
      "Proportion of flagged lines for Lyon: 0.00 %\n",
      "Proportion of flagged lines for Marseille: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "drop_nonconform_lines(paris, 2)\n",
    "drop_nonconform_lines(lyon, 2)\n",
    "drop_nonconform_lines(marseille, 2)\n",
    "\n",
    "prop_printer(paris, 'Paris', 2)\n",
    "prop_printer(lyon, 'Lyon', 2)\n",
    "prop_printer(marseille, 'Marseille', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_logement</th>\n",
       "      <th>surface</th>\n",
       "      <th>prix</th>\n",
       "      <th>type_l</th>\n",
       "      <th>ville</th>\n",
       "      <th>arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appartement Paris 17</td>\n",
       "      <td>3 pieces  1 chambre  51.84m2</td>\n",
       "      <td>535 000 eur</td>\n",
       "      <td>appartement</td>\n",
       "      <td>Paris</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appartement Paris 15</td>\n",
       "      <td>3 pieces  2 chambres  40.77m2</td>\n",
       "      <td>470 000 eur</td>\n",
       "      <td>appartement</td>\n",
       "      <td>Paris</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appartement Paris 13</td>\n",
       "      <td>2 pieces  1 chambre  39m2</td>\n",
       "      <td>385 000 eur</td>\n",
       "      <td>appartement</td>\n",
       "      <td>Paris</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>appartement Paris 13</td>\n",
       "      <td>2 pieces  1 chambre  36.03m2</td>\n",
       "      <td>383 000 eur</td>\n",
       "      <td>appartement</td>\n",
       "      <td>Paris</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>appartement Paris 10</td>\n",
       "      <td>2 pieces  1 chambre  40.7m2</td>\n",
       "      <td>399 000 eur</td>\n",
       "      <td>appartement</td>\n",
       "      <td>Paris</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          type_logement                         surface         prix   \n",
       "0  appartement Paris 17    3 pieces  1 chambre  51.84m2  535 000 eur  \\\n",
       "1  appartement Paris 15   3 pieces  2 chambres  40.77m2  470 000 eur   \n",
       "2  appartement Paris 13       2 pieces  1 chambre  39m2  385 000 eur   \n",
       "3  appartement Paris 13    2 pieces  1 chambre  36.03m2  383 000 eur   \n",
       "4  appartement Paris 10     2 pieces  1 chambre  40.7m2  399 000 eur   \n",
       "\n",
       "        type_l  ville arr  \n",
       "0  appartement  Paris  17  \n",
       "1  appartement  Paris  15  \n",
       "2  appartement  Paris  13  \n",
       "3  appartement  Paris  13  \n",
       "4  appartement  Paris  10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paris = pd.read_csv(paris, encoding='latin-1', header = None, sep = ';')\n",
    "df_lyon = pd.read_csv(lyon, encoding='latin-1', header = None, sep = ';')\n",
    "df_marseille = pd.read_csv(marseille, encoding='latin-1', header = None, sep = ';')\n",
    "df_final = pd.concat([df_paris, df_marseille, df_lyon], ignore_index=True)\n",
    "df_final = df_final.rename(columns = {0:'type_logement', 1: 'surface', 2: 'prix'})\n",
    "app_mask = df_final['type_logement'].str.contains('appartement')\n",
    "df_final = df_final[app_mask]\n",
    "df_split = df_final.type_logement.str.split(' ', expand = True)\n",
    "df_split = df_split.rename(columns = {0: 'type_l', 1 : 'ville', 2: 'arr'})\n",
    "df_final = pd.concat([df_final, df_split], axis = 1)\n",
    "df = df_final.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
